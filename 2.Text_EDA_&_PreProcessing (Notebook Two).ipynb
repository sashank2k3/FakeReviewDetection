{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT DATA EXPLORATION AND PRE-PROCESSING\n",
    "\n",
    "(Hussain et al., 2020) It has been observed from the literature that Spam Review detection using linguistic method uses only review text for spotting the spam review [37], [38]. It is usually performed binary classifcation in which the review is classifed as``spam or not spam``, and in our case studying the verified and unverified reviews for the detection of fake reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "\n",
    "In this notebook, we have done another EDA, however this time we focused on the input variable review_text itself, rather than the other attributes. Firstly columns depicting the character, word, stopcount, punctuation and the capital letter counts were added to guage the frequency of each of them, which then we later cleaned them during the text processing stage. \n",
    "\n",
    "It is important to note that before that, the necessary duplicates and NULL values were also taken care of, and then the reviews were then saved into a new file, where in the next notebook it is going to be utlized for model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRARIES \n",
    "# !pip install wordcloud\n",
    "# !pip install textblob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import  PorterStemmer \n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOADING DATASET \n",
    "df = pd.read_csv(\"data and pickle files/updated_data_new.csv\",encoding=\"latin1\") #due to special charas should be encoded as latin 1\n",
    "#REMOVE MAX\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING UNWANTED COLUMN\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE-CHECK NULL AND DUPLICATES\n",
    "\n",
    "In our first EDA with the entire dataset, the duplicates within the reviews were not detected, which could be due to the other columns having slightly different values. Since we have removed the other columns and all we have left are the review_centric values, we need to double check on whether there are duplicated reviews within the dataset, which we can remove accordingly to remove potential bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "Initially, in the first data exploration in the old cvs file, we have tried finding out the duplicates within this dataset. However, initially it did not yield any results. To double check on whether this dataset really has no duplicates, the selected columns were added to aid see if there are actually any duplicates within this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#CHECK TOTAL DUPLICATE OCCURENCES\n",
    "dup = df.duplicated().sum()\n",
    "print(\"Number of duplicates in dataset: \", dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL Values\n",
    "re-checking for NULL values to check if any needs to be filled up or dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#DROP review_title\n",
    "df.drop([\"review_title\",\"review_date\"], axis=1, \n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles are actually not mandatory in amazon reviews, and hence there are multiple missing values within the review_title. For this project, we are not going to be utlizing this dataset, and hence it is going to be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA ON THE REVIEW TEXT\n",
    "\n",
    "We have conducted an in-depth review surrounding the background of the Amazon dataset, and this time the ``review_text`` itself is going to be taken a further look. To aid in our pre-processing, certain columns will be added to understand certain instances the sentences have. Those include the counts of:\n",
    "1. Word\n",
    "2. Characters (with spaces)\n",
    "3. Stopwords\n",
    "4. Punctuations\n",
    "5. Uppercase characters\n",
    "\n",
    "After the columns are added, necessary ``summary statistics`` will be conducted to get an idea on how the pre-processing will take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORD COUNT\n",
    "df['total words'] = df['review_text'].apply(lambda i: len(str(i).split(\" \")))\n",
    "\n",
    "#CHARACTER COUNT\n",
    "df['total characters'] = df['review_text'].str.len() #spaces are included\n",
    "\n",
    "#STOPWORDS COUNT\n",
    "sw = set(stopwords.words('english'))\n",
    "df['total stopwords'] = df['review_text'].str.split().apply(lambda i: len(set(i) & sw))\n",
    "\n",
    "#PUNCTUATION AND SPECIAL CHARA COUNT\n",
    "count_p = lambda p1,p2: sum([1 for i in p1 if i in p2])\n",
    "df['total punctuations'] = df.review_text.apply(lambda p: count_p(p, string.punctuation))\n",
    "\n",
    "#UPPERCASE CHARA COUNT\n",
    "df['total uppercases'] = df['review_text'].str.findall(r'[A-Z]').str.len() #findall - finds all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.head() #UPDATED "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Readings\n",
    "1. The mean characters within the entire dataset happens to be at 177, averaging at about 33 words per review.\n",
    "2. On average, there are about 9 stop words, and within the sentences there are about 4 punctuations.\n",
    "3. As for the uppercase letters, from the mean value it is safe to assume that most of the reviews utlized their uppercases as Sentence Case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df.groupby(\"verified_purchase\").describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Findings\n",
    "1. Overall, we can see that False reviews have more words per character than True Values, where False values have an average of 50 words and 268 characters, while True values have about 14 words on average and 77 characters per review.\n",
    "2. Witin the Fake reviews, it can be observed that there are more stopwords as well, than True reviews.\n",
    "3. Since they are longer sentences in False values, it can be seen that there are more punctuations and Sentence case than True values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#PIE CHART ON VERFIED PURCHASES -two\n",
    "colors = ['#FED8B1','#79BAEC']\n",
    "plt.figure(figsize=(4,4))\n",
    "label = df['verified_purchase'].value_counts()\n",
    "plt.pie(label.values,colors = colors, labels=label.index, autopct= '%1.1f%%', startangle=90)\n",
    "plt.title('True and False Reviews Count', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the duplicates, we can see that the percentages of the True and False values are still near equal, and hence we can say that the dataset is balanced. Taking a closer look into the graph, there are more False values and True values within the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sns.catplot(x ='review_rating',kind=\"count\", hue=\"verified_purchase\", data=df)\n",
    "plt.xlabel(\"review_rating\")\n",
    "plt.ylabel(\"count of reviews\")\n",
    "plt.title(\"Review_Rating Grouped by Verified_Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cols = [\"verified_purchase\", \"review_text\"]\n",
    "vprt = df[cols] #making a subset of the dataframe-\n",
    "\n",
    "#FILTERING BASED ON TRUE AND FALSE VP\n",
    "checkTrue = vprt[\"verified_purchase\"] == True\n",
    "filtered_true = vprt[checkTrue]\n",
    "\n",
    "checkFalse = vprt[\"verified_purchase\"] == False\n",
    "filtered_false = vprt[checkFalse]\n",
    "\n",
    "\n",
    "#AVERAGE REVIEW LENGTH BASED ON TRUE AND FALSE VP\n",
    "false_average_length = filtered_false[\"review_text\"].apply(len).mean()\n",
    "true_average_length = filtered_true[\"review_text\"].apply(len).mean()\n",
    "\n",
    "#PLOTTING THE GRAPH\n",
    "x = [true_average_length,false_average_length]\n",
    "y = [\"True\", \"False\"]\n",
    "sns.barplot(x)\n",
    "plt.xlabel(\"Average Length of Reviews\")\n",
    "plt.ylabel(\"verified_purchases\")\n",
    "plt.title(\"Average Length of Reviews based on Verified Purchases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that 5 star rating is still the highest, and that true reviews still are more than false values within 5 star. Sentiment is still highly positive within this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING\n",
    "\n",
    "Text preprocessing is a technique for cleaning text data and preparing it for use in a model. Text data comprises noise in the form of emotions, punctuation, and text in a different case, among other things. When it comes to Human Language, there are many different ways to communicate the same thing, and this is only the beginning of the difficulty. Machines cannot comprehend words; they want numbers, thus we must convert text to numbers efficiently.\n",
    "\n",
    "\n",
    "From the summary statistics conducted, we can see that the noise mentioned are having occurences within the review text, and hence the pre-processing will be conducted accordingly.\n",
    "\n",
    "> To Do\n",
    "1. Drop unwanted columns\n",
    "2. Lowercasing\n",
    "3. Remove Stopwords\n",
    "4. Remove Punctuations and Special charas\n",
    "5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#DROP UNNECESSARY COLUMNS\n",
    "df.drop([\"total words\",\"total characters\",\n",
    "         \"total stopwords\",\"total punctuations\",\n",
    "         \"total uppercases\",\"review_rating\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are going to be only utlizing review_text and verified_purchase for our classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing \n",
    "\n",
    "The ``review_text`` is going to be cleaned and standardized so that when implemented within the model, the model can be optimized at its best. This step takes the longest since it is in base of trial and error.\n",
    "\n",
    "DONE IN THIS STAGE:\n",
    "1. Spelling is corrected\n",
    "2. tokenization,\n",
    "3. removing stopwords, punctuations, special charas\n",
    "4. lowercasing\n",
    "5. stemming\n",
    "6. removing top 3 common and rare words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#CORRECT SPELLING\n",
    "df.review_text.apply(lambda i: ''.join(TextBlob(i).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING THE STOPWORDS,PUNCTUATIONS, LOWERCASING, AND STEMMING OF THE SENTENCES\n",
    "def text_preprocessing(text):\n",
    "    removed_special_characters = re.sub(\"[^a-zA-Z]\", \" \", str(text))\n",
    "    tokens = removed_special_characters.lower().split()\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    cleaned = []\n",
    "    stemmed = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in sw:\n",
    "            cleaned.append(token)\n",
    "            \n",
    "    for token in cleaned:\n",
    "        token = stemmer.stem(token)\n",
    "        stemmed.append(token)\n",
    "\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['review_text'] = df['review_text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['review_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#CHECK RARE WORDS\n",
    "r = pd.Series(' '.join(df['review_text']).split()).value_counts()[-10:]\n",
    "print(\"RARE WORDS:\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#CHECK TOP COMMON WORDS\n",
    "words = '' \n",
    "for i in df[\"review_text\"]: \n",
    "    tokens = i.split()   \n",
    "    words += \" \".join(tokens)+\" \"\n",
    "\n",
    "    \n",
    "word_cloud = WordCloud(width = 700, height = 700, \n",
    "                       background_color ='white', \n",
    "                       min_font_size = 10).generate(words) \n",
    "plt.figure(figsize = (5, 5)) \n",
    "plt.imshow(word_cloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing common and rare words\n",
    "common = pd.Series(' '.join(df['review_text']).split()).value_counts()[:3]\n",
    "common = list(common.index)\n",
    "df['review_text'] = df['review_text'].apply(lambda i: \" \".join(i for i in i.split() if i not in common))\n",
    "\n",
    "rare = pd.Series(' '.join(df['review_text']).split()).value_counts()[-3:]\n",
    "rare = list(rare.index)\n",
    "df['review_text'] = df['review_text'].apply(lambda i: \" \".join(i for i in i.split() if i not in rare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#WORDCLOUD - UPDATED TOP WORDS\n",
    "words = '' \n",
    "for i in df[\"review_text\"]: \n",
    "    tokens = i.split()   \n",
    "    words += \" \".join(tokens)+\" \"\n",
    "\n",
    "    \n",
    "word_cloud = WordCloud(width = 700, height = 700, background_color ='white', min_font_size = 10).generate(words) \n",
    "plt.figure(figsize = (5, 5)) \n",
    "plt.imshow(word_cloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the top 3 common word (it was removed since it would remove its meaning from the entire thing), we are left with the current top 10 words. As seen from above, we can see that the sentiment of it is quite positive, meaning that this dataset is dealing with many positive-centric reviews. The general polarity is thus, positive, and needs to be kept in mind for analysis later. It is to be noted that due to the lack of negative reviews in this case can cause for there to be discrepencies when, for instance a negative value is set to be identified as \"fake\" or \"real\", and thus can be added as a limitation to this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "df[\"review_text\"] = df[\"review_text\"].apply(lambda x: tokenizer.tokenize(str(x)))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING UPDATED DATAFRAME AS .csv FILE\n",
    "df.to_csv('data and pickle files/cleaned_data_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
